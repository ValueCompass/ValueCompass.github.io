---
layout: talks
title: "价值观罗盘：如何让大模型与人类价值观对齐?"
date: 2024-04-11  0
image: images/talks/talk1/cover.jpg
permalink: /talks/base_align
talk_url: https://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&mid=2649499350&idx=1&sn=26a0db299e290bf34ac1fc4909b79d0b&chksm=82c7cf52b5b04644acc0ae8e7cc4221b827a8b883041281e8173f23977e4e5dcb554006ab4d8&mpshare=1&scene=1&srcid=0607CMwKY9qFJANncc7xeOFM&sharer_shareinfo=64976deb74d306dbf36f02d2db82248f&sharer_shareinfo_first=64976deb74d306dbf36f02d2db82248f#rd
---

随着人工智能技术的快速发展和能力的不断增强，大模型已经逐步应用于人们的日常生活。但这同时也带来了很多新的潜在风险，进一步凸显了大模型与人类价值观对齐问题的紧迫性。然而，人工智能应该与哪些价值观进行对齐？又该如何对齐？这些问题至今还没有明确的答案。 

为了解决这些挑战，微软亚洲研究院提出了价值观罗盘（Value Compass）项目，从交叉学科的角度切入，充分借鉴伦理学和社会学中的理论，以解决对价值观的定义、评测和对齐问题。本文将深度解析大模型价值观的对齐现状，并介绍微软亚洲研究院在这一领域取得的最新研究成果——基于施瓦茨人类基本价值理论的 BaseAlign 对齐算法。